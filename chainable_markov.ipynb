{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chainable Markov Chain Model\n",
    "\n",
    "Trains a model that learns a chainable composition operation in latent space for Markov chain prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup: Clone repo and import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/sughodke/markov-learned.git\n",
    "%cd markov-learned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from model import (\n",
    "    CharVocab,\n",
    "    NgramDataset,\n",
    "    ChainableMarkovModel,\n",
    "    collate_ngrams,\n",
    "    train,\n",
    "    generate,\n",
    ")\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/shakespeare.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "print(f\"Corpus size: {len(text):,} characters\")\n",
    "\n",
    "vocab = CharVocab(text)\n",
    "print(f\"Vocabulary size: {vocab.vocab_size}\")\n",
    "\n",
    "# Train/validation split\n",
    "split_idx = int(len(text) * 0.9)\n",
    "train_text = text[:split_idx]\n",
    "val_text = text[split_idx:]\n",
    "\n",
    "train_dataset = NgramDataset(train_text, vocab)\n",
    "val_dataset = NgramDataset(val_text, vocab)\n",
    "print(f\"Train samples: {len(train_dataset):,}\")\n",
    "print(f\"Val samples: {len(val_dataset):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "d_latent = 128\n",
    "d_hidden = 512\n",
    "dropout = 0.1\n",
    "batch_size = 128\n",
    "epochs = 50\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_ngrams, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_ngrams, num_workers=2)\n",
    "\n",
    "model = ChainableMarkovModel(vocab_size=vocab.vocab_size, d_latent=d_latent, d_hidden=d_hidden, dropout=dropout)\n",
    "print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = train(model, train_loader, val_loader, device, epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = \"Follow those\"\n",
    "print(f\"Seed: '{seed}'\")\n",
    "print(\"-\" * 40)\n",
    "print(generate(model, vocab, seed, max_length=200, temperature=0.8, device=device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chainability Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for n in [2, 3, 4, 5]:\n",
    "        seq = vocab.encode(\"a\" * n)\n",
    "        latent = model.forward_chain([seq], device)\n",
    "        print(f\"{n}-gram: latent shape = {latent.shape}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
